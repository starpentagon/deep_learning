# Deep Neural Network modelの動作検証の概要
* 以下の主要3タスクの有名モデルの動作方法を検証
  1. classification: ResNet50
  2. detection: SSD
  3. segmentation: FCN, Mask R-CNN
* 手元の画像で主要タスクを動かした結果を共有
* おまけ: Jupyter notebookからリモートで分析を行う方法の紹介

# 動作させる上でのハマりポイント
* GPUの認識
  * GPUのCompute Compatibility, CUDA, cuDNNのバージョンを揃える必要あり
  * AWSのDeep Learning AMIを使うと設定済みなので楽
  * そもそも学習をしないのであればCPUモードで確認するのが無難
* python, pythonモジュール, FW(TensorFlow, Keras)の相性がめちゃくちゃシビア
  * Python環境の切り分けはマスト
    * システムライブラリの相性もあるのでdocker等でOSレベルで切り分けた方が無難
  * 各種モジュール群を最新版にしないと動かないケースと最新版固有のバグがあり悩ましい
  * メジャーな実装を使うのが情報が多く解決しやすい
  * 個人が公開しているコードは雑な実装が多くかなりバグが多い
  * Linuxでソースからビルドしていた時代を彷彿とさせる課題解決力が必要
* 学習済みモデルが提供されているか
  * 提供されていなければ自前で学習する必要がある
  * データセットのダウンロードやデータセットをハンドリングするツールをインストールする必要がありハードルが一段上がる
  * CPUだと学習に時間がかかりすぎる（segmentationでFCNを使おうとしたがCPUだと学習に25日かかる計算になり断念）ためGPUを使う必要がありハードルが上がる
  * 学習済みモデルが提供されていてもモデルのインターフェースが変わっているケースがあり(detectionのSSDでハマった)、個別にトラブルシュートが必要。ここでもメジャーなアルゴリズム、実装であれば情報が入手しやすい

## Classification: ResNet
* Kerasで学習済みモデルを含めて提供されており非常に容易に利用可能
* Tutorialが丁寧
* 独自データでの再学習も簡単

## Detection: SSD
* メジャー実装はKeras1版でKeras2には非対応
* Keras1環境を別途作るかKeras2版を探す必要あり
  * Keras2版を探した
* Keras 2.1.3 -> Keras 2.1.4でモデルのインターフェースが変わったらしく公開されている学習済みモデルはそのままでは使えない。
  * Keras 2.1.4用に修正したコードを見つけて対応

## Segmentation: FCN
* 最初はFCNを使おうとした
* 公開されているコードはPython2前提でハマる
* 事前学習モデルが公開されておらずMS COCOというデータセットで自前で学習が必要
  * MS COCOを扱うツールのインストールでビルドエラー多発
  * 実はGitレポジトリが変更になっていて古いレポジトリを見ていた
  * さらに内部で使っているkeras-contrib関連でエラー多発
  * keras-contribの最新版を(condaではなく)pipで入れると動いた
  * 学習しようとしたらGPUを使ってくれない
  * CPUだと25日かかる計算になり断念

## Segmentation: Mask R-CNN
* GitHub上で詳細な説明がのっている
* git clone -> 「notebookで実行」で一発で動いた！
* と思ったが、画像により結構な頻度(70%くらいで)python kernelが死ぬ
  * Math kernel libraryが悪さをしているという情報もあり使わないようにしてみたが解決せず
  * (川上くんコメント)Jupyter notebookで利用していると詳細なエラーが表示されない。terminalで動かしてエラーを確認して一つずつ潰す必要あり。
  * (川上くんコメント)Mask R-CNNは有志がC++実装を公開しており高速。公式実装以上に動かすのは大変だがコンペ等ではよく用いられている。

# まとめ
## 環境構築
* Tutorialの世界とその外は天国と地獄の差
* 色々文句を言ったが1週間でclassification, detection, segmentationのアルゴリズムを動かせる状態になるというのはすごいこと
  * 別に自分で実装した訳ではなくほとんど「適当なgitレポジトリを見つける」「最新版で動かすための差分情報をググる」だけ
  * ちょっと知識があって、ITリテラシーがあれば誰でもできる？
  * その中で「他人とは違う何か」って何になる？Quickな検証とコンサルか？？
* FWで隠蔽されている分、エラーが出た時の解析が困難
  * メジャーなアルゴリズム、実装なら情報が見つかることが多い
  * かつてメジャーだったアルゴリズムも他に良いモデルが見つかると情報が一気に減る印象
  * 結局、最新のFWにした上で「最もホットな」アルゴリズムを使うしかない？
  * あっという間に状況が変わるので追従し続けるのは得策でない気もする
  * タスクごとにOut of Boxで使える環境は価値があると実感

## Classification
  * かなりお手軽
  * 転移学習（自分のデータで再学習）も結構簡単
  * 成熟期に入ったといっても良い気がする
  * ただし、ImageNetで学習されたモデルはラベルに偏りがある（特にpersonが含まれていない）

## Detection
* SSDだと認識したラベルにそもそも違和感あり
* 時代はYolo(最近v3が登場)に移っている気がする
* PASCAL VOCで学習されているのでやはりラベルに偏りが若干ある気がする
* 上空からとった写真に対してはまったく物体検知しなかったのは少し気になる（学習データにあまり含まれていないからか？たまたまか？）

## Segmentation
### FCN
* もはや歴史的な価値しかないFCNを今、動かそうとするのは得策ではない
### Mask R-CNN
* Mask R-CNNも上空からとった写真に対してはまったく物体検知しなかったのは少し気になる
  * (川上くんコメント)モデルのハイパーパラメタをチューニングすると検知できるようになると思う
* 高確率でpython kernelが死ぬので正直まだまだ不安定
* それでも動くと思わず「おおー！」と言ってしまうくらい良くできた結果になっている！
  * 特に物体に輪郭を綺麗に分離できていてて感動した

## タスク全般
* 画像認識は誰でも良し悪しを「主観的に」評価できる
  * Mask R-CNNは率直に感動した
  * 実際に手元の画像を認識させた結果を冷静にみると「ん？」となる結果も多い
  * 学習フェーズでは正解ラベルの一致／不一致で誤差を評価するが、本当は間違えた時の「概念的な近さ」も考慮する必要がある
* 論文やプレスリリースで使われている画像はかなりうまく行った例が切り取られている印象
  * 実際に動かして得手不得手を肌感覚で持っておくことは重要
* 事前学習に使ったデータセットから外れた世界はうまく認識できていないことが多い
* 素の実力以上に成果が喧伝されている？（3層Neural Networkが出た時と同じ！）
  * 感動を呼び込みやすい反面、失望も引き起こしやすい
  * 恐ろしくネガティブな事例が出てきてしまうかも。。。
* 実際にデータセットのサンプル画像を眺めてみるのと実際に手元の画像を色々入れてみると実感として理解できる
  * 理解は深まったと思うが差異化していくにはどうすれば対外的に伝わりやすいのか？？？
